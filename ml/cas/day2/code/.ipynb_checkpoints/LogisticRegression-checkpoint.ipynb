{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# encoding:utf-8\n",
    "import random\n",
    "import numpy\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LogisticRegression(object):\n",
    "    # 给定训练数据（x, y), 学习率（alpha）和正则化权重（lam）\n",
    "    def __init__(self, X, Y, alpha=0.0005, lam=0.1, printIter=True):\n",
    "        x = numpy.array(X)\n",
    "        m, n = x.shape # 获得样本个数和每个样本特征个数\n",
    "\n",
    "        # 对数据进预处理， 使得数据满足标准正态分布\n",
    "        self.xMean = numpy.mean(x, axis=0)\n",
    "        self.xStd = numpy.std(x, axis=0)\n",
    "        x = (x - self.xMean) / self.xStd\n",
    "\n",
    "        # 为了便于处理偏置项b，做的特殊处理，即输入数据补常数1\n",
    "        const = numpy.array([1] * m).reshape(m, 1)\n",
    "        self.X = numpy.append(const, x, axis=1)\n",
    "\n",
    "        self.Y = numpy.array(Y)\n",
    "        self.alpha = alpha\n",
    "        self.lam = lam\n",
    "        self.theta = numpy.array([0.0] * (n + 1))\n",
    "\n",
    "        self.printIter = printIter\n",
    "        print \"lambda=\", self.lam\n",
    "\n",
    "    # sigmoid函数定义\n",
    "    def _sigmoid(self, x):\n",
    "        z = 1.0 / (1.0 + numpy.exp((-1) * x))\n",
    "        return z\n",
    "\n",
    "    # 定义损失函数\n",
    "    def _costFunc(self):\n",
    "        m, n = self.X.shape\n",
    "        h_theta = self._sigmoid(numpy.dot(self.X, self.theta)) # 模型预测结果\n",
    "\n",
    "        # 每个样本的模型损失函数\n",
    "        cost1 = (-1) * self.Y * numpy.log(h_theta)\n",
    "        cost2 = (1.0 - self.Y) * numpy.log(1.0 - h_theta)\n",
    "\n",
    "        # 加上参数的正则项\n",
    "        cost = (\n",
    "            sum(cost1 - cost2) + 0.5 * self.lam * sum(self.theta[1:] ** 2)) / m\n",
    "        return cost\n",
    "\n",
    "    # 通过求导，更新参数\n",
    "    def _gradientDescend(self, iters):\n",
    "        \"\"\"\n",
    "        X: 输入数据特征\n",
    "        Y: 输出目标\n",
    "        theta: 模型参数\n",
    "        alpha: 学习率\n",
    "        lam: 正则化权重\n",
    "       \"\"\"\n",
    "\n",
    "        m, n = self.X.shape\n",
    "        for i in xrange(0, iters):\n",
    "            theta_temp = self.theta # 参数原始值\n",
    "\n",
    "            h_theta = self._sigmoid(numpy.dot(self.X, self.theta)) # 模型预测结果\n",
    "            diff = h_theta - self.Y\n",
    "            self.theta[0] = theta_temp[0] - self.alpha * \\\n",
    "                (1.0 / m) * sum(diff * self.X[:, 0]) # 偏置项求导及其更新\n",
    "\n",
    "            for j in xrange(1, n):\n",
    "                val = theta_temp[\n",
    "                    j] - self.alpha * (1.0 / m) * (sum(diff * self.X[:, j]) + self.lam * m * theta_temp[j])\n",
    "                # 参数求导及其更新\n",
    "                self.theta[j] = val\n",
    "            cost = self._costFunc() # 计算当前参数值的情况下，损失函数是多少，损失函数逐步下降才说明程序可能正确\n",
    "\n",
    "            if self.printIter:\n",
    "                print \"Iteration\", i, \"\\tcost=\", cost\n",
    "\n",
    "    def run(self, iters, printIter=True):\n",
    "        self.printIter = printIter\n",
    "        self._gradientDescend(iters)\n",
    "\n",
    "    # 给定输入数据，根据模型（模型定义及其参数值），计算预测结果\n",
    "    def predict(self, X):\n",
    "        m, n = X.shape\n",
    "        x = numpy.array(X)\n",
    "        # 数据预处理\n",
    "        x = (x - self.xMean) / self.xStd\n",
    "        # 补常数1\n",
    "        const = numpy.array([1] * m).reshape(m, 1)\n",
    "        X = numpy.append(const, x, axis=1)\n",
    "        # 计算预测得分\n",
    "        pred = self._sigmoid(numpy.dot(X, self.theta))\n",
    "        numpy.putmask(pred, pred >= 0.5, 1.0) # 得分大于等于0.5则是正例\n",
    "        numpy.putmask(pred, pred < 0.5, 0.0)\n",
    "\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda= 0.1\n",
      "训练错误率= 0.0766666666667 测试错误率= 0.05\n",
      " \n",
      "lambda= 0.1\n",
      "训练错误率= 0.0722222222222 测试错误率= 0.1\n",
      " \n",
      "lambda= 0.1\n",
      "训练错误率= 0.0744444444444 测试错误率= 0.08\n",
      " \n",
      "lambda= 0.1\n",
      "训练错误率= 0.0755555555556 测试错误率= 0.06\n",
      " \n",
      "lambda= 0.1\n",
      "训练错误率= 0.0733333333333 测试错误率= 0.08\n",
      " \n",
      "lambda= 0.1\n",
      "训练错误率= 0.0733333333333 测试错误率= 0.09\n",
      " \n",
      "lambda= 0.1\n",
      "训练错误率= 0.0761111111111 测试错误率= 0.065\n",
      " \n",
      "lambda= 0.1\n",
      "训练错误率= 0.0761111111111 测试错误率= 0.065\n",
      " \n",
      "lambda= 0.1\n",
      "训练错误率= 0.0772222222222 测试错误率= 0.065\n",
      " \n",
      "lambda= 0.1\n",
      "训练错误率= 0.0738888888889 测试错误率= 0.09\n",
      " \n",
      "summary:\n",
      "平均训练错误率 = 7.48888888889 %\n",
      "平均测试错误率 = 7.45 %\n"
     ]
    }
   ],
   "source": [
    "# 读入数据\n",
    "data = numpy.genfromtxt('input.csv', delimiter=',')\n",
    "# response is in the first column\n",
    "Y = data[:, 0] # 类标签数据\n",
    "X = data[:, 1:] # 实例特征数据\n",
    "\n",
    "\n",
    "# 随机打散数据，X和Y同步打散\n",
    "m = len(Y)\n",
    "index = range(0, m)\n",
    "random.shuffle(index)\n",
    "X = X[index, :]\n",
    "Y = Y[index]\n",
    "\n",
    "# 使用10折交叉验证\n",
    "nfold = 10\n",
    "foldSize = int(m / nfold)\n",
    "\n",
    "# 看每次的错误情况，然后求平均\n",
    "trainErr = [0.0] * nfold\n",
    "testErr = [0.0] * nfold\n",
    "allIndex = range(0, m)\n",
    "for i in range(0, nfold):\n",
    "    # 每次训练和测试\n",
    "    testIndex = range((foldSize * i), foldSize * (i + 1))\n",
    "    trainIndex = list(set(allIndex) - set(testIndex))\n",
    "\n",
    "    trainX = X[trainIndex, :] #训练数据\n",
    "    trainY = Y[trainIndex]\n",
    "    testX = X[testIndex, :] #测试数据\n",
    "    testY = Y[testIndex]\n",
    "\n",
    "    # 超参数设置\n",
    "    alpha = 0.05\n",
    "    lam = 0.1\n",
    "    model = LogisticRegression(trainX, trainY, alpha, lam)\n",
    "    model.run(400, printIter=False) #训练模型\n",
    "\n",
    "    # 在训练集中测试模型效果\n",
    "    trainPred = model.predict(trainX)\n",
    "    trainErr[i] = float(sum(trainPred != trainY)) / len(trainY)\n",
    "\n",
    "    # 在测试集中测试模型效果\n",
    "    testPred = model.predict(testX)\n",
    "    testErr[i] = float(sum(testPred != testY)) / len(testY)\n",
    "\n",
    "    print \"训练错误率=\", trainErr[i], \"测试错误率=\", testErr[i]\n",
    "    print \" \"\n",
    "\n",
    "# 总体结果\n",
    "print \"summary:\"\n",
    "print \"平均训练错误率 =\", numpy.mean(trainErr) * 100, \"%\"\n",
    "print \"平均测试错误率 =\", numpy.mean(testErr) * 100, \"%\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
