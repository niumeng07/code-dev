{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named pycrfsuite",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-ef1c9ea3539f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLabelBinarizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpycrfsuite\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named pycrfsuite"
     ]
    }
   ],
   "source": [
    "# encoding:utf8\n",
    "from itertools import chain\n",
    "import nltk\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import sklearn\n",
    "import pycrfsuite\n",
    "\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用CoNLL 2000 数据构建NP抽取系统 to build a NER system\n",
    "\n",
    "- 使用NLTK内部提供的CoNLL2000语料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train.txt', 'test.txt']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.conll2000.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 936 ms, sys: 992 ms, total: 1.93 s\n",
      "Wall time: 1.97 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_sents = list(nltk.corpus.conll2000.iob_sents('train.txt'))\n",
    "test_sents = list(nltk.corpus.conll2000.iob_sents('test.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "原始数据格式，方便提取特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'Confidence', u'NN', u'B-NP'),\n",
       " (u'in', u'IN', u'B-PP'),\n",
       " (u'the', u'DT', u'B-NP'),\n",
       " (u'pound', u'NN', u'I-NP'),\n",
       " (u'is', u'VBZ', u'B-VP'),\n",
       " (u'widely', u'RB', u'I-VP'),\n",
       " (u'expected', u'VBN', u'I-VP'),\n",
       " (u'to', u'TO', u'I-VP'),\n",
       " (u'take', u'VB', u'I-VP'),\n",
       " (u'another', u'DT', u'B-NP'),\n",
       " (u'sharp', u'JJ', u'I-NP'),\n",
       " (u'dive', u'NN', u'I-NP'),\n",
       " (u'if', u'IN', u'B-SBAR'),\n",
       " (u'trade', u'NN', u'B-NP'),\n",
       " (u'figures', u'NNS', u'I-NP'),\n",
       " (u'for', u'IN', u'B-PP'),\n",
       " (u'September', u'NNP', u'B-NP'),\n",
       " (u',', u',', u'O'),\n",
       " (u'due', u'JJ', u'B-ADJP'),\n",
       " (u'for', u'IN', u'B-PP'),\n",
       " (u'release', u'NN', u'B-NP'),\n",
       " (u'tomorrow', u'NN', u'B-NP'),\n",
       " (u',', u',', u'O'),\n",
       " (u'fail', u'VB', u'B-VP'),\n",
       " (u'to', u'TO', u'I-VP'),\n",
       " (u'show', u'VB', u'I-VP'),\n",
       " (u'a', u'DT', u'B-NP'),\n",
       " (u'substantial', u'JJ', u'I-NP'),\n",
       " (u'improvement', u'NN', u'I-NP'),\n",
       " (u'from', u'IN', u'B-PP'),\n",
       " (u'July', u'NNP', u'B-NP'),\n",
       " (u'and', u'CC', u'I-NP'),\n",
       " (u'August', u'NNP', u'I-NP'),\n",
       " (u\"'s\", u'POS', u'B-NP'),\n",
       " (u'near-record', u'JJ', u'I-NP'),\n",
       " (u'deficits', u'NNS', u'I-NP'),\n",
       " (u'.', u'.', u'O')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sents[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征模板"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "    features = [\n",
    "        'bias',\n",
    "        'word.lower=' + word.lower(),\n",
    "        'word[-3:]=' + word[-3:],\n",
    "        'word[-2:]=' + word[-2:],\n",
    "        'word.isupper=%s' % word.isupper(),\n",
    "        'word.istitle=%s' % word.istitle(),\n",
    "        'word.isdigit=%s' % word.isdigit(),\n",
    "        'postag=' + postag,\n",
    "        'postag[:2]=' + postag[:2],\n",
    "    ]\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        features.extend([\n",
    "            '-1:word.lower=' + word1.lower(),\n",
    "            '-1:word.istitle=%s' % word1.istitle(),\n",
    "            '-1:word.isupper=%s' % word1.isupper(),\n",
    "            '-1:postag=' + postag1,\n",
    "            '-1:postag[:2]=' + postag1[:2],\n",
    "        ])\n",
    "    else:\n",
    "        features.append('BOS')\n",
    "        \n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        features.extend([\n",
    "            '+1:word.lower=' + word1.lower(),\n",
    "            '+1:word.istitle=%s' % word1.istitle(),\n",
    "            '+1:word.isupper=%s' % word1.isupper(),\n",
    "            '+1:postag=' + postag1,\n",
    "            '+1:postag[:2]=' + postag1[:2],\n",
    "        ])\n",
    "    else:\n",
    "        features.append('EOS')\n",
    "                \n",
    "    return features\n",
    "\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, postag, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, postag, label in sent]    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "特征示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bias',\n",
       " u'word.lower=confidence',\n",
       " u'word[-3:]=nce',\n",
       " u'word[-2:]=ce',\n",
       " 'word.isupper=False',\n",
       " 'word.istitle=True',\n",
       " 'word.isdigit=False',\n",
       " u'postag=NN',\n",
       " u'postag[:2]=NN',\n",
       " 'BOS',\n",
       " u'+1:word.lower=in',\n",
       " '+1:word.istitle=False',\n",
       " '+1:word.isupper=False',\n",
       " u'+1:postag=IN',\n",
       " u'+1:postag[:2]=IN']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent2features(train_sents[0])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "抽取特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 416 ms, sys: 3.81 s, total: 4.23 s\n",
      "Wall time: 4.25 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train = [sent2features(s) for s in train_sents]\n",
    "y_train = [sent2labels(s) for s in train_sents]\n",
    "\n",
    "X_test = [sent2features(s) for s in test_sents]\n",
    "y_test = [sent2labels(s) for s in test_sents]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练\n",
    "- 构建模型\n",
    "- 导入学习数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 688 ms, sys: 2.82 s, total: 3.5 s\n",
      "Wall time: 3.51 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainer = pycrfsuite.Trainer(verbose=False)\n",
    "\n",
    "for xseq, yseq in zip(X_train, y_train):\n",
    "    trainer.append(xseq, yseq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "设置训练参数：使用L-BFGSsu算法(默认值)并用Elastic Net进行正则化（本质就是L1和L2一起用）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.set_params({\n",
    "    'c1': 1.0,   # coefficient for L1 penalty\n",
    "    'c2': 1e-3,  # coefficient for L2 penalty\n",
    "    'max_iterations': 50,  # stop earlier\n",
    "\n",
    "    # include transitions that are possible, but not observed\n",
    "    'feature.possible_transitions': True\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feature.minfreq',\n",
       " 'feature.possible_states',\n",
       " 'feature.possible_transitions',\n",
       " 'c1',\n",
       " 'c2',\n",
       " 'max_iterations',\n",
       " 'num_memories',\n",
       " 'epsilon',\n",
       " 'period',\n",
       " 'delta',\n",
       " 'linesearch',\n",
       " 'max_linesearch']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 模型训练的参数\n",
    "trainer.params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 35.4 s, sys: 652 ms, total: 36.1 s\n",
      "Wall time: 36.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainer.train('conll2000-np.crfsuite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练模型保存到问句中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw------- 1 dl dl 513K 9月  15 08:22 ./conll2000-np.crfsuite\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lh ./conll2000-np.crfsuite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看模型训练情况：使用logparser查看。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'active_features': 11099,\n",
       " 'error_norm': 1002.760167,\n",
       " 'feature_norm': 93.39015,\n",
       " 'linesearch_step': 1.0,\n",
       " 'linesearch_trials': 1,\n",
       " 'loss': 21714.5293,\n",
       " 'num': 50,\n",
       " 'scores': {},\n",
       " 'time': 0.662}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.logparser.last_iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "logparser记录的其他信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 {'loss': 21769.328496, 'error_norm': 835.229788, 'linesearch_trials': 1, 'active_features': 11241, 'num': 49, 'time': 0.677, 'scores': {}, 'linesearch_step': 1.0, 'feature_norm': 92.739679}\n"
     ]
    }
   ],
   "source": [
    "print len(trainer.logparser.iterations), trainer.logparser.iterations[-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型预测\n",
    "- 创建模型\n",
    "- 导入模型文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.closing at 0x7f963cbbb550>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger = pycrfsuite.Tagger()\n",
    "tagger.open('conll2000-np.crfsuite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对一个句子进行标注"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rockwell International Corp. 's Tulsa unit said it signed a tentative agreement extending its contract with Boeing Co. to provide structural parts for Boeing 's 747 jetliners .\n",
      "预测标签: B-NP I-NP I-NP B-NP I-NP I-NP B-VP B-NP B-VP B-NP I-NP I-NP B-VP B-NP I-NP B-PP B-NP I-NP B-VP I-VP B-NP I-NP B-PP B-NP B-NP I-NP I-NP O\n",
      "真实标签:   B-NP I-NP I-NP B-NP I-NP I-NP B-VP B-NP B-VP B-NP I-NP I-NP B-VP B-NP I-NP B-PP B-NP I-NP B-VP I-VP B-NP I-NP B-PP B-NP B-NP I-NP I-NP O\n"
     ]
    }
   ],
   "source": [
    "example_sent = test_sents[0]\n",
    "print(' '.join(sent2tokens(example_sent)))\n",
    "\n",
    "print \"预测标签:\", ' '.join(tagger.tag(sent2features(example_sent)))\n",
    "print \"真实标签:  \", ' '.join(sent2labels(example_sent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bio_classification_report(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Classification report for a list of BIO-encoded sequences.\n",
    "    It computes token-level metrics and discards \"O\" labels.\n",
    "    \n",
    "    Note that it requires scikit-learn 0.15+ (or a version from github master)\n",
    "    to calculate averages properly!\n",
    "    \"\"\"\n",
    "    lb = LabelBinarizer()\n",
    "    y_true_combined = lb.fit_transform(list(chain.from_iterable(y_true)))\n",
    "    y_pred_combined = lb.transform(list(chain.from_iterable(y_pred)))\n",
    "        \n",
    "    tagset = set(lb.classes_) - {'O'}\n",
    "    tagset = sorted(tagset, key=lambda tag: tag.split('-', 1)[::-1])\n",
    "    class_indices = {cls: idx for idx, cls in enumerate(lb.classes_)}\n",
    "    \n",
    "    return classification_report(\n",
    "        y_true_combined,\n",
    "        y_pred_combined,\n",
    "        labels = [class_indices[cls] for cls in tagset],\n",
    "        target_names = tagset,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对测试集中所有数据进行预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 488 ms, sys: 56 ms, total: 544 ms\n",
      "Wall time: 559 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = [tagger.tag(xseq) for xseq in X_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "按照各类标签类型进行评价"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "     B-ADJP       0.78      0.74      0.76       438\n",
      "     I-ADJP       0.76      0.66      0.71       167\n",
      "     B-ADVP       0.84      0.81      0.82       866\n",
      "     I-ADVP       0.65      0.58      0.62        89\n",
      "    B-CONJP       0.56      0.56      0.56         9\n",
      "    I-CONJP       0.71      0.77      0.74        13\n",
      "     B-INTJ       1.00      0.50      0.67         2\n",
      "      B-LST       0.00      0.00      0.00         5\n",
      "      I-LST       0.00      0.00      0.00         2\n",
      "       B-NP       0.96      0.96      0.96     12422\n",
      "       I-NP       0.96      0.96      0.96     14376\n",
      "       B-PP       0.96      0.98      0.97      4811\n",
      "       I-PP       0.89      0.65      0.75        48\n",
      "      B-PRT       0.75      0.76      0.76       106\n",
      "     B-SBAR       0.88      0.83      0.85       535\n",
      "     I-SBAR       0.17      0.75      0.27         4\n",
      "       B-VP       0.96      0.95      0.96      4658\n",
      "       I-VP       0.94      0.96      0.95      2646\n",
      "\n",
      "avg / total       0.95      0.95      0.95     41197\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dl/.pyenv/versions/2.7.12/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(bio_classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
